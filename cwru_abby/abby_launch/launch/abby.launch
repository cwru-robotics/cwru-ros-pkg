<launch>
    <!-- Start the urdf server and publish tfs -->
	<param name="robot_description" command="$(find xacro)/xacro.py '$(find abby_description)/urdf/abby.xacro'" />
	<node name="robot_state_publisher" pkg="robot_state_publisher" type="state_publisher" />
	<node pkg="tf" type="static_transform_publisher" name="base_frame_broadcaster" args="-0.04203954 -0.07963916 0.11 1.570795 0 0 base_link frame1 100" />
	<node pkg="tf" type="static_transform_publisher" name="jaw_tip1_broadcaster" args="0 0.0125 0.044 0 0 0 gripper_jaw_1 gripper_jaw_1_tip 100" />
	<node pkg="tf" type="static_transform_publisher" name="jaw_tip2_broadcaster" args="0 0.0125 0.044 0 0 0 gripper_jaw_2 gripper_jaw_2_tip 100" />
	
    <!--Only start the robot driver nodes if the robot is actually running.
        Otherwise, start the joint_state_publisher -->
    <arg name="real_robot" default="True" />
    <arg name="arm" default="True" />
    <include file="$(find abby_launch)/launch/actuators.launch" if="$(arg real_robot)">
        <arg name="arm" value="$(arg arm)" />
	</include>
    <node name="joint_state_publisher" pkg="joint_state_publisher" type="joint_state_publisher" unless="$(arg real_robot)"></node>
    
    <!-- If joint_gui is set, use the gui sliders to set joint positions -->
	<arg name="joint_gui" default="False" />
	<param name="use_gui" value="$(arg joint_gui)"/>
	
	<!-- If rviz is set, start rviz -->
	<arg name="rviz" default="False" />
    <include file="$(find abby_launch)/launch/rviz.launch" if="$(arg rviz)">
    </include>

    <!-- If no_kinect not set, start kinect -->
    <arg name="no_kinect" default="False" />
    <include file="$(find openni_launch)/launch/openni.launch" unless="$(arg no_kinect)">
        <arg name="publish_tf" value="false" />
    </include>
    <!--param name="camera/driver/depth_registration" value="true" /-->
    <param name="camera/driver/data_skip" value="3" />
  
  <!-- self filter Kinect points -->
  <node pkg="robot_self_filter_color" type="self_filter_color" respawn="true" name="color_self_filter" output="screen" unless="$(arg no_kinect)">
      <remap from="cloud_in" to="/camera/depth_registered/points" />
      <remap from="cloud_out" to="/camera/depth_registered/object_modeling_points_filtered" />
      <param name="sensor_frame" type="string" value="/camera_rgb_optical_frame" />
      <param name="subsample_value" type="double" value=".005"/>
     <rosparam command="load" file="$(find abby_config)/config/arm/self_filter.yaml" />
  </node>
    <!-- Really awesome kinect monitor to kill the openni_node stupidness -->
    <!-- node pkg="pr2_object_manipulation_launch" type="kinect_monitor.py" name="kinect_monitor" unless="$(arg no_kinect)">
        <param name="kinect_node_name" value="camera_nodelet_manager" />
        <param name="grace_period" value="15" />
        <remap from="camera_info" to="/camera/rgb/camera_info" />
    </node-->
</launch>
